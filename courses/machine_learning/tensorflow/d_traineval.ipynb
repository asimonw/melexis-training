{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2d. Distributed training and monitoring </h1>\n",
    "\n",
    "In this notebook, we refactor to call ```train_and_evaluate``` instead of hand-coding our ML pipeline. This allows us to carry out evaluation as part of our training loop instead of as a separate step. It also adds in failure-handling that is necessary for distributed training capabilities.\n",
    "\n",
    "We also use TensorBoard to monitor the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import datalab.bigquery as bq\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Input </h2>\n",
    "\n",
    "Read data created in Lab1a, but this time make it more general, so that we are reading in batches.  Instead of using Pandas, we will use Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
    "LABEL_COLUMN = 'fare_amount'\n",
    "DEFAULTS = [[0.0], [-74.0], [40.0], [-74.0], [40.7], [1.0], ['nokey']]\n",
    "\n",
    "def read_dataset(filename, mode, batch_size = 512):\n",
    "  def _input_fn():\n",
    "    def decode_csv(value_column):\n",
    "      columns = tf.decode_csv(value_column, record_defaults = DEFAULTS)\n",
    "      features = dict(zip(CSV_COLUMNS, columns))\n",
    "      label = features.pop(LABEL_COLUMN)\n",
    "      return features, label\n",
    "    \n",
    "    # Create list of files that match pattern\n",
    "    file_list = tf.gfile.Glob(filename)\n",
    "\n",
    "    # Create dataset from file list\n",
    "    dataset = tf.data.TextLineDataset(file_list).map(decode_csv)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        num_epochs = None # indefinitely\n",
    "        dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "    else:\n",
    "        num_epochs = 1 # end-of-input after this\n",
    " \n",
    "    dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create features out of input data </h2>\n",
    "\n",
    "For now, pass these through.  (same as previous lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = [\n",
    "    tf.feature_column.numeric_column('pickuplon'),\n",
    "    tf.feature_column.numeric_column('pickuplat'),\n",
    "    tf.feature_column.numeric_column('dropofflat'),\n",
    "    tf.feature_column.numeric_column('dropofflon'),\n",
    "    tf.feature_column.numeric_column('passengers'),\n",
    "]\n",
    "\n",
    "def add_more_features(feats):\n",
    "  # Nothing to add (yet!)\n",
    "  return feats\n",
    "\n",
    "feature_cols = add_more_features(INPUT_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> train_and_evaluate </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "  feature_placeholders = {\n",
    "    'pickuplon' : tf.placeholder(tf.float32, [None]),\n",
    "    'pickuplat' : tf.placeholder(tf.float32, [None]),\n",
    "    'dropofflat' : tf.placeholder(tf.float32, [None]),\n",
    "    'dropofflon' : tf.placeholder(tf.float32, [None]),\n",
    "    'passengers' : tf.placeholder(tf.float32, [None]),\n",
    "  }\n",
    "  features = {\n",
    "      key: tf.expand_dims(tensor, -1)\n",
    "      for key, tensor in feature_placeholders.items()\n",
    "  }\n",
    "  return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "  estimator = tf.estimator.LinearRegressor(\n",
    "                       model_dir = output_dir,\n",
    "                       feature_columns = feature_cols)\n",
    "  train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = read_dataset('./taxi-train.csv', mode = tf.estimator.ModeKeys.TRAIN),\n",
    "                       max_steps = num_train_steps)\n",
    "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "  eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = read_dataset('./taxi-valid.csv', mode = tf.estimator.ModeKeys.EVAL),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = 10,  # evaluate every N seconds\n",
    "                       exporters = exporter)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f25700c3400>, '_train_distribute': None, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_experimental_distribute': None, '_save_summary_steps': 100, '_num_worker_replicas': 1, '_save_checkpoints_steps': None, '_tf_random_seed': None, '_service': None, '_global_id_in_cluster': 0, '_keep_checkpoint_max': 5, '_model_dir': 'taxi_trained', '_device_fn': None, '_task_type': 'worker', '_protocol': None, '_num_ps_replicas': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_eval_distribute': None, '_is_chief': True, '_master': '', '_save_checkpoints_secs': 600, '_evaluation_master': ''}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 102464.62, step = 1\n",
      "INFO:tensorflow:global_step/sec: 28.2584\n",
      "INFO:tensorflow:loss = 51073.176, step = 101 (3.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8115\n",
      "INFO:tensorflow:loss = 45654.652, step = 201 (3.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.1959\n",
      "INFO:tensorflow:loss = 48794.555, step = 301 (3.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.8359\n",
      "INFO:tensorflow:loss = 51960.27, step = 401 (3.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.3117\n",
      "INFO:tensorflow:loss = 72301.84, step = 501 (3.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.8933\n",
      "INFO:tensorflow:loss = 84264.36, step = 601 (2.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.8898\n",
      "INFO:tensorflow:loss = 45807.01, step = 701 (2.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4011\n",
      "INFO:tensorflow:loss = 53114.01, step = 801 (2.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2244\n",
      "INFO:tensorflow:loss = 45473.586, step = 901 (2.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.3532\n",
      "INFO:tensorflow:loss = 65942.88, step = 1001 (2.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.5944\n",
      "INFO:tensorflow:loss = 75539.33, step = 1101 (2.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1084\n",
      "INFO:tensorflow:loss = 62258.77, step = 1201 (3.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5545\n",
      "INFO:tensorflow:loss = 39546.03, step = 1301 (3.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.4099\n",
      "INFO:tensorflow:loss = 34427.29, step = 1401 (3.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.854\n",
      "INFO:tensorflow:loss = 29302.682, step = 1501 (3.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3076\n",
      "INFO:tensorflow:loss = 54237.605, step = 1601 (3.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.2183\n",
      "INFO:tensorflow:loss = 34753.08, step = 1701 (3.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4509\n",
      "INFO:tensorflow:loss = 44616.566, step = 1801 (3.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.337\n",
      "INFO:tensorflow:loss = 51013.64, step = 1901 (3.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.069\n",
      "INFO:tensorflow:loss = 37839.64, step = 2001 (3.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8849\n",
      "INFO:tensorflow:loss = 66012.83, step = 2101 (3.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.9142\n",
      "INFO:tensorflow:loss = 45280.457, step = 2201 (3.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.1305\n",
      "INFO:tensorflow:loss = 52959.594, step = 2301 (3.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.8015\n",
      "INFO:tensorflow:loss = 74392.234, step = 2401 (3.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.2382\n",
      "INFO:tensorflow:loss = 64168.047, step = 2501 (3.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.6996\n",
      "INFO:tensorflow:loss = 51732.844, step = 2601 (3.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.0141\n",
      "INFO:tensorflow:loss = 85476.35, step = 2701 (3.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.6494\n",
      "INFO:tensorflow:loss = 43596.914, step = 2801 (3.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.6996\n",
      "INFO:tensorflow:loss = 57255.527, step = 2901 (3.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.8039\n",
      "INFO:tensorflow:loss = 75644.79, step = 3001 (3.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.3127\n",
      "INFO:tensorflow:loss = 42655.37, step = 3101 (3.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.9898\n",
      "INFO:tensorflow:loss = 34376.305, step = 3201 (3.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4934\n",
      "INFO:tensorflow:loss = 73623.945, step = 3301 (3.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.2351\n",
      "INFO:tensorflow:loss = 66494.125, step = 3401 (3.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.0259\n",
      "INFO:tensorflow:loss = 38822.82, step = 3501 (3.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.811\n",
      "INFO:tensorflow:loss = 36253.547, step = 3601 (3.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.3492\n",
      "INFO:tensorflow:loss = 50008.43, step = 3701 (3.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5395\n",
      "INFO:tensorflow:loss = 59979.86, step = 3801 (3.271 sec)\n",
      "INFO:tensorflow:loss = 45440.984, step = 3901 (3.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4366\n",
      "INFO:tensorflow:loss = 33143.316, step = 4001 (3.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.635\n",
      "INFO:tensorflow:loss = 54911.82, step = 4101 (3.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.374\n",
      "INFO:tensorflow:loss = 63381.24, step = 4201 (2.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.8021\n",
      "INFO:tensorflow:loss = 51525.562, step = 4301 (2.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.7089\n",
      "INFO:tensorflow:loss = 37206.844, step = 4401 (2.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.992\n",
      "INFO:tensorflow:loss = 56631.914, step = 4501 (3.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.9877\n",
      "INFO:tensorflow:loss = 41874.516, step = 4601 (3.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.5407\n",
      "INFO:tensorflow:loss = 55448.508, step = 4701 (3.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.8111\n",
      "INFO:tensorflow:loss = 37431.46, step = 4801 (3.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5897\n",
      "INFO:tensorflow:loss = 32922.344, step = 4901 (3.171 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-12T19:10:42Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-12-19:10:43\n",
      "INFO:tensorflow:Saving dict for global step 5000: average_loss = 100.29811, global_step = 5000, label/mean = 11.372183, loss = 39392.082, prediction/mean = 10.975887\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: taxi_trained/model.ckpt-5000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'passengers': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>, 'pickuplon': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'pickuplat': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'dropofflon': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'dropofflat': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'passengers': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>, 'pickuplon': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'pickuplat': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'dropofflon': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'dropofflat': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: taxi_trained/export/exporter/temp-b'1560366643'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 42973.42.\n"
     ]
    }
   ],
   "source": [
    "# Run training    \n",
    "OUTDIR = 'taxi_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "train_and_evaluate(OUTDIR, num_train_steps = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Monitoring with TensorBoard </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 5544. Click <a href=\"/_proxy/58653/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logdir</th>\n",
       "      <th>pid</th>\n",
       "      <th>port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./taxi_trained</td>\n",
       "      <td>1877</td>\n",
       "      <td>60777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./taxi_trained</td>\n",
       "      <td>5544</td>\n",
       "      <td>58653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           logdir   pid   port\n",
       "0  ./taxi_trained  1877  60777\n",
       "1  ./taxi_trained  5544  58653"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('./taxi_trained')\n",
    "TensorBoard().list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The link does not yet work in AI Notebooks. Do the following instead:\n",
    "1. Open the Launcher tab (if you don't see it, File > New Launcher)\n",
    "1. Click the Tensorboard launcher\n",
    "\n",
    "Tensorboard should now open and you should also see it the Tensorboards tab on the left. If it doesn't open, make sure you've installed the jupyter-tensorboard library. To do that:\n",
    "1. Open the Launcher tab and click Terminal (or from the menu, Git > Open Terminal)\n",
    "1. Run `pip install jupyter-tensorboard`\n",
    "1. Restart the instance (GCP Console > AI Notebooks > Stop, Start), then refresh this page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to stop TensorBoard\n",
    "for pid in TensorBoard.list()['pid']:\n",
    "    TensorBoard().stop(pid)\n",
    "    print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
